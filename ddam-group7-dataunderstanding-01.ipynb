{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-16T15:17:23.981197Z","iopub.execute_input":"2022-12-16T15:17:23.981930Z","iopub.status.idle":"2022-12-16T15:17:24.025834Z","shell.execute_reply.started":"2022-12-16T15:17:23.981831Z","shell.execute_reply":"2022-12-16T15:17:24.024629Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/earthquakes/consolidated_data.csv\n/kaggle/input/earthquakes/consolidated_data/consolidated_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:17:24.027961Z","iopub.execute_input":"2022-12-16T15:17:24.029087Z","iopub.status.idle":"2022-12-16T15:18:17.165380Z","shell.execute_reply.started":"2022-12-16T15:17:24.029039Z","shell.execute_reply":"2022-12-16T15:18:17.164051Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting py4j==0.10.9.5\n  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845513 sha256=9d04612e6564fcf0a9cb67acf9e00c737bacba33314f8cd768f47ccf6b85113d\n  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\n  Attempting uninstall: py4j\n    Found existing installation: py4j 0.10.9.7\n    Uninstalling py4j-0.10.9.7:\n      Successfully uninstalled py4j-0.10.9.7\nSuccessfully installed py4j-0.10.9.5 pyspark-3.3.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pyspark","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:17.167133Z","iopub.execute_input":"2022-12-16T15:18:17.167603Z","iopub.status.idle":"2022-12-16T15:18:17.232987Z","shell.execute_reply.started":"2022-12-16T15:18:17.167558Z","shell.execute_reply":"2022-12-16T15:18:17.231763Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from pyspark.sql import SparkSession\nspark=SparkSession.builder.master(\"local[*]\").getOrCreate()\nspark","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:17.235938Z","iopub.execute_input":"2022-12-16T15:18:17.236389Z","iopub.status.idle":"2022-12-16T15:18:23.637672Z","shell.execute_reply.started":"2022-12-16T15:18:17.236344Z","shell.execute_reply":"2022-12-16T15:18:23.636361Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","output_type":"stream"},{"name":"stdout","text":"22/12/16 15:18:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<pyspark.sql.session.SparkSession at 0x7f560761fc90>","text/html":"\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://233bc9a49e71:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "},"metadata":{}}]},{"cell_type":"markdown","source":"# 01 : DataUnderstanding\nThe objective of the present Task is to perform Data Reading, Description and Understanding of the present Dataset.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.sql import SQLContext, SparkSession","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:23.639176Z","iopub.execute_input":"2022-12-16T15:18:23.640288Z","iopub.status.idle":"2022-12-16T15:18:24.447768Z","shell.execute_reply.started":"2022-12-16T15:18:23.640241Z","shell.execute_reply":"2022-12-16T15:18:24.446630Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/earthquakes/consolidated_data.csv'\n#df2 = spark.read.option(\"delimiter\", \",\").csv(path)\n#df2.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:24.449123Z","iopub.execute_input":"2022-12-16T15:18:24.449443Z","iopub.status.idle":"2022-12-16T15:18:24.454481Z","shell.execute_reply.started":"2022-12-16T15:18:24.449414Z","shell.execute_reply":"2022-12-16T15:18:24.453386Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = spark.read.option(\"escape\",\"\\\"\").csv(path, header='true', inferSchema='true')","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:24.455653Z","iopub.execute_input":"2022-12-16T15:18:24.456029Z","iopub.status.idle":"2022-12-16T15:18:48.498491Z","shell.execute_reply.started":"2022-12-16T15:18:24.455974Z","shell.execute_reply":"2022-12-16T15:18:48.495676Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"df.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:48.499590Z","iopub.execute_input":"2022-12-16T15:18:48.499871Z","iopub.status.idle":"2022-12-16T15:18:49.099558Z","shell.execute_reply.started":"2022-12-16T15:18:48.499844Z","shell.execute_reply":"2022-12-16T15:18:49.095944Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"22/12/16 15:18:48 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n Header: , time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\n Schema: _c0, time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\nExpected: _c0 but found: \nCSV file: file:///kaggle/input/earthquakes/consolidated_data.csv\n+------+--------------------+------------------+-------------------+-----+----+-------+----+-----+-------------------+----+------+------------+--------------------+--------------------+------------+-------------------+----------+-------------------+------+---------+--------------+---------+\n|   _c0|                time|          latitude|          longitude|depth| mag|magType| nst|  gap|               dmin| rms|   net|          id|             updated|               place|        type|    horizontalError|depthError|           magError|magNst|   status|locationSource|magSource|\n+------+--------------------+------------------+-------------------+-----+----+-------+----+-----+-------------------+----+------+------------+--------------------+--------------------+------------+-------------------+----------+-------------------+------+---------+--------------+---------+\n|988481| 1970-01-01 00:00:00|37.003501899999996|       -117.9968338|  0.0| 0.0|     mh| 0.0| null|               null|null|    ci|  ci37038459|2016-04-02 20:22:...|29km NE of Indepe...|  sonic boom|               null|      null|               null|   0.0| reviewed|            ci|       ci|\n|988480| 1970-01-01 00:00:00|35.642787899999995|       -120.9336014|  5.0|1.99|     mh| 2.0| null|               null|null|    ci|  ci11092098|2016-01-29 01:43:...|11km SSW of Lake ...|  earthquake|               null|      null|               null|   0.0| reviewed|            ci|       ci|\n|988478| 1970-01-01 00:00:00|        34.1645203|-118.18503570000001|  0.0| 0.0|     mh|null| null|               null|null|    ci|  ci15086796|2016-04-02 17:20:...|4km S of La Canad...|  earthquake|               null|      null|               null|   0.0| reviewed|            ci|       ci|\n|988477| 1970-01-01 00:00:00|        33.8364944|-116.78186799999999|  0.0| 0.0|     mh|null| null|               null|null|    ci|  ci14891508|2016-04-02 14:10:...|9km S of Cabazon, CA|  sonic boom|               null|      null|               null|   0.0| reviewed|            ci|       ci|\n|988476| 1970-01-01 00:00:00|         33.208477|-115.47699740000002|  5.0| 0.0|     mh|null| null|               null|null|    ci|  ci10925125|2016-04-02 04:32:...|5km SE of Niland, CA|  sonic boom|               null|      null|               null|   0.0| reviewed|            ci|       ci|\n|988475| 1970-01-01 00:00:00|         32.663559|-116.10502620000001|  0.0| 0.0|     mh| 0.0| null|               null|null|    ci|  ci15099228|2016-04-02 14:10:...|13km SW of Ocotil...|  sonic boom|               null|      null|               null|   0.0| reviewed|            ci|       ci|\n|988479| 1970-01-01 00:00:00|        35.3544502|-115.48489380000001|  0.0| 0.5|     mh| 0.0| null|               null|null|    ci|  ci10169902|2016-01-29 01:19:...|30km SSW of Primm...|quarry blast|               null|      null|               null|   0.0| reviewed|            ci|       ci|\n|988474|1970-01-01 06:16:...|           46.2765|            -118.36|-0.26| 2.3|     md| 6.0|303.0|               0.52|0.14|    uw|  uw10836008|2016-07-24 23:40:...|          Washington|  earthquake|               0.41|      0.24|               0.12|   0.0| reviewed|            uw|       uw|\n|988473|1970-01-01 06:44:...|        46.3328333|-118.39116670000001|-0.26| 2.6|     md| 6.0|299.0|             0.4814|0.15|    uw|  uw10836013|2016-07-24 23:40:...|          Washington|  earthquake|0.14400000000000002|      0.09|               0.21|   0.0| reviewed|            uw|       uw|\n|988472|1970-01-01 15:13:...|        32.7071667|           -115.417|  6.0|2.75|     mh| 4.0|214.0|             0.6036|0.58|    ci|   ci3324951|2016-01-29 01:29:...|8km NE of Mexical...|  earthquake|                4.6|     31.61|              0.084|   6.0| reviewed|            ci|       ci|\n|988471| 1970-01-01 17:11:00|             -29.4|           -177.169| 35.0| 5.6|     mw|null| null|               null|null|iscgem|iscgem799588| 2015-05-13 18:53:03|Kermadec Islands,...|  earthquake|               null|      null|               null|  null|automatic|        iscgem|   iscgem|\n|988470|1970-01-01 19:49:...|        37.4333333|          -118.7435|  6.0|3.69|     ml|10.0|211.0|               null|0.58|    ci|   ci3324952|2016-01-29 01:33:...|27km WNW of West ...|  earthquake|               3.24|     31.61|0.22399999999999998|   7.0| reviewed|            ci|       ci|\n|988469|1970-01-02 08:58:...|           46.7495|          -119.3715|1.869| 1.5|     md| 6.0| 93.0|             0.1063|0.15|    uw|  uw10836018|2016-07-24 23:40:...|          Washington|  earthquake|              0.578|      1.91|               0.12|   0.0| reviewed|            uw|       uw|\n|988468|1970-01-02 10:45:...|34.205999999999996|-119.69566670000002|  6.0|3.14|     ml|11.0|205.0|             0.2347|0.59|    ci|   ci3324955|2016-01-29 01:38:...|24km S of Santa B...|  earthquake|               2.45|     31.61|              0.157|  10.0| reviewed|            ci|       ci|\n|988467|1970-01-02 21:47:...|        35.7351667|-117.73366670000001| 1.65|2.61|     ml| 6.0| 96.0|             0.1368|0.73|    ci|   ci3324957|2016-01-29 01:43:...|12km NE of Inyoke...|  earthquake|               2.69|      6.53|              0.152|   3.0| reviewed|            ci|       ci|\n|988466|1970-01-03 19:48:...|           33.9605|          -116.8305|  6.0|3.16|     ml| 9.0|103.0|0.45399999999999996|0.53|    ci|   ci3324959|2016-01-29 01:43:...|6km NE of Banning...|  earthquake|               1.67|     31.61|               0.13|   5.0| reviewed|            ci|       ci|\n|988465|1970-01-04 02:27:...|           34.3335|-116.84333329999998|  6.0|2.74|     ml| 9.0|120.0|             0.5565|0.56|    ci|   ci3324960|2016-01-29 01:13:...|8km N of Big Bear...|  earthquake|               1.12|     31.61|              0.064|   5.0| reviewed|            ci|       ci|\n|988464| 1970-01-04 17:00:41|            24.185| 102.54299999999999| 11.3| 7.1|     mw|null| null|               null|null|iscgem|iscgem799712|2017-04-26 17:23:...|       Yunnan, China|  earthquake|               null|      null|               null|  null|automatic|        iscgem|   iscgem|\n|988463| 1970-01-05 11:49:10|            23.984| 102.73200000000001| 15.0| 5.9|     mw|null| null|               null|null|iscgem|iscgem799745|2017-04-26 17:23:...|       Yunnan, China|  earthquake|               null|      null|               null|  null|automatic|        iscgem|   iscgem|\n|988462|1970-01-05 12:04:...|        33.2428333|           -115.986|  6.0|3.04|     ml| 4.0|156.0|             0.7425|0.32|    ci|   ci3324834|2016-01-29 01:24:...|7km SSW of Salton...|  earthquake|               1.31|     31.61|               0.21|   4.0| reviewed|            ci|       ci|\n+------+--------------------+------------------+-------------------+-----+----+-------+----+-----+-------------------+----+------+------------+--------------------+--------------------+------------+-------------------+----------+-------------------+------+---------+--------------+---------+\nonly showing top 20 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:49.100778Z","iopub.execute_input":"2022-12-16T15:18:49.101221Z","iopub.status.idle":"2022-12-16T15:18:49.116537Z","shell.execute_reply.started":"2022-12-16T15:18:49.101186Z","shell.execute_reply":"2022-12-16T15:18:49.115470Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"root\n |-- _c0: integer (nullable = true)\n |-- time: timestamp (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- depth: double (nullable = true)\n |-- mag: double (nullable = true)\n |-- magType: string (nullable = true)\n |-- nst: double (nullable = true)\n |-- gap: double (nullable = true)\n |-- dmin: double (nullable = true)\n |-- rms: double (nullable = true)\n |-- net: string (nullable = true)\n |-- id: string (nullable = true)\n |-- updated: timestamp (nullable = true)\n |-- place: string (nullable = true)\n |-- type: string (nullable = true)\n |-- horizontalError: double (nullable = true)\n |-- depthError: double (nullable = true)\n |-- magError: double (nullable = true)\n |-- magNst: double (nullable = true)\n |-- status: string (nullable = true)\n |-- locationSource: string (nullable = true)\n |-- magSource: string (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Objectives\n1. Get a general Idea of the Dataset and its features\n2. Spot Missing values\n3. Spot eventual mistakes/outliers ","metadata":{}},{"cell_type":"markdown","source":"# 1. Get a general Idea of the Dataset and its features","metadata":{}},{"cell_type":"code","source":"n_rows = df.count()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:49.120213Z","iopub.execute_input":"2022-12-16T15:18:49.120551Z","iopub.status.idle":"2022-12-16T15:18:51.151609Z","shell.execute_reply.started":"2022-12-16T15:18:49.120513Z","shell.execute_reply":"2022-12-16T15:18:51.150398Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"n_cols = len(df.columns)","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:51.152819Z","iopub.execute_input":"2022-12-16T15:18:51.153236Z","iopub.status.idle":"2022-12-16T15:18:51.185458Z","shell.execute_reply.started":"2022-12-16T15:18:51.153195Z","shell.execute_reply":"2022-12-16T15:18:51.184193Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(f'Dimension of the Dataframe is: {(n_rows,n_cols)}')","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:51.186866Z","iopub.execute_input":"2022-12-16T15:18:51.188453Z","iopub.status.idle":"2022-12-16T15:18:51.195150Z","shell.execute_reply.started":"2022-12-16T15:18:51.188407Z","shell.execute_reply":"2022-12-16T15:18:51.194050Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Dimension of the Dataframe is: (3272774, 23)\n","output_type":"stream"}]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:51.197453Z","iopub.execute_input":"2022-12-16T15:18:51.198395Z","iopub.status.idle":"2022-12-16T15:18:51.208587Z","shell.execute_reply.started":"2022-12-16T15:18:51.198352Z","shell.execute_reply":"2022-12-16T15:18:51.207438Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['_c0',\n 'time',\n 'latitude',\n 'longitude',\n 'depth',\n 'mag',\n 'magType',\n 'nst',\n 'gap',\n 'dmin',\n 'rms',\n 'net',\n 'id',\n 'updated',\n 'place',\n 'type',\n 'horizontalError',\n 'depthError',\n 'magError',\n 'magNst',\n 'status',\n 'locationSource',\n 'magSource']"},"metadata":{}}]},{"cell_type":"code","source":"# Get more information about the meaning of the columns \n#https://earthquake.usgs.gov/earthquakes/feed/v1.0/csv.php","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:51.210817Z","iopub.execute_input":"2022-12-16T15:18:51.211887Z","iopub.status.idle":"2022-12-16T15:18:51.219776Z","shell.execute_reply.started":"2022-12-16T15:18:51.211842Z","shell.execute_reply":"2022-12-16T15:18:51.218608Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# first create a copy of df \ndf_copy = df.alias('df_copy')","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:51.221995Z","iopub.execute_input":"2022-12-16T15:18:51.222901Z","iopub.status.idle":"2022-12-16T15:18:51.241470Z","shell.execute_reply.started":"2022-12-16T15:18:51.222858Z","shell.execute_reply":"2022-12-16T15:18:51.240286Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# We want to drop duplicates \ndf = df.dropDuplicates([col for col in df.columns if col != '_c0'])","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:51.243529Z","iopub.execute_input":"2022-12-16T15:18:51.244387Z","iopub.status.idle":"2022-12-16T15:18:51.280445Z","shell.execute_reply.started":"2022-12-16T15:18:51.244343Z","shell.execute_reply":"2022-12-16T15:18:51.279054Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# NB: this is the new length of the df after dropping duplicates\ndf.count()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:18:51.282098Z","iopub.execute_input":"2022-12-16T15:18:51.283290Z","iopub.status.idle":"2022-12-16T15:19:33.344937Z","shell.execute_reply.started":"2022-12-16T15:18:51.283244Z","shell.execute_reply":"2022-12-16T15:19:33.343503Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"3256955"},"metadata":{}}]},{"cell_type":"markdown","source":"The number of records is 3.256.955, which is the same as the number of distinct records on the column _c0. \nConsidering the above statement and taking into consideration the fact that 'id' is a string providing the following information : \" *'id': A unique identifier for the event. This is the current preferred id for the event, and may change over time. See the \"ids\" GeoJSON format property.* \", \nwe decide to remove the following columns:","metadata":{}},{"cell_type":"code","source":"# df id is a string and does not provide any important information\ndf.select('id').take(5)","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:19:33.346716Z","iopub.execute_input":"2022-12-16T15:19:33.347184Z","iopub.status.idle":"2022-12-16T15:20:05.775925Z","shell.execute_reply.started":"2022-12-16T15:19:33.347138Z","shell.execute_reply":"2022-12-16T15:20:05.774734Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[Row(id='usp00003ku'),\n Row(id='usp00017cz'),\n Row(id='usp00050hn'),\n Row(id='usp0005273'),\n Row(id='usp00008pp')]"},"metadata":{}}]},{"cell_type":"code","source":"# First drop the following columns which are not useful for sure\nto_drop = ['locationSource', 'id',\n 'magSource', 'updated']","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:20:05.777578Z","iopub.execute_input":"2022-12-16T15:20:05.778063Z","iopub.status.idle":"2022-12-16T15:20:05.784315Z","shell.execute_reply.started":"2022-12-16T15:20:05.777996Z","shell.execute_reply":"2022-12-16T15:20:05.781842Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df = df.drop(*(col for col in to_drop))","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:20:05.785895Z","iopub.execute_input":"2022-12-16T15:20:05.786375Z","iopub.status.idle":"2022-12-16T15:20:06.145282Z","shell.execute_reply.started":"2022-12-16T15:20:05.786328Z","shell.execute_reply":"2022-12-16T15:20:06.144265Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:20:06.146530Z","iopub.execute_input":"2022-12-16T15:20:06.146870Z","iopub.status.idle":"2022-12-16T15:20:06.156300Z","shell.execute_reply.started":"2022-12-16T15:20:06.146838Z","shell.execute_reply":"2022-12-16T15:20:06.155076Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['_c0',\n 'time',\n 'latitude',\n 'longitude',\n 'depth',\n 'mag',\n 'magType',\n 'nst',\n 'gap',\n 'dmin',\n 'rms',\n 'net',\n 'place',\n 'type',\n 'horizontalError',\n 'depthError',\n 'magError',\n 'magNst',\n 'status']"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2: Spot Missing values + spot eventual mistakes/outliers","metadata":{}},{"cell_type":"code","source":"# NaNs\nfrom pyspark.sql.functions import col,sum\ndf.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns)).show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:20:06.157836Z","iopub.execute_input":"2022-12-16T15:20:06.158483Z","iopub.status.idle":"2022-12-16T15:20:48.436640Z","shell.execute_reply.started":"2022-12-16T15:20:06.158435Z","shell.execute_reply":"2022-12-16T15:20:48.433873Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"22/12/16 15:20:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n Header: , time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\n Schema: _c0, time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\nExpected: _c0 but found: \nCSV file: file:///kaggle/input/earthquakes/consolidated_data.csv\n","output_type":"stream"},{"name":"stderr","text":"[Stage 15:>                                                         (0 + 4) / 5]\r","output_type":"stream"},{"name":"stdout","text":"22/12/16 15:20:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n","output_type":"stream"},{"name":"stderr","text":"[Stage 17:=============================>                            (3 + 3) / 6]\r","output_type":"stream"},{"name":"stdout","text":"+---+----+--------+---------+-----+------+-------+------+------+-------+------+---+-----+----+---------------+----------+--------+------+------+\n|_c0|time|latitude|longitude|depth|   mag|magType|   nst|   gap|   dmin|   rms|net|place|type|horizontalError|depthError|magError|magNst|status|\n+---+----+--------+---------+-----+------+-------+------+------+-------+------+---+-----+----+---------------+----------+--------+------+------+\n|  0|   0|       0|        0|    9|155698| 166609|876988|834294|1339697|210659|  0|   11|   0|        1524519|    603806| 1772000|983988|     1|\n+---+----+--------+---------+-----+------+-------+------+------+-------+------+---+-----+----+---------------+----------+--------+------+------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# remove all the rows presenting Nans on \"mag\" and \"magType\"\ndf = df.na.drop(subset=[\"mag\", \"magType\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:20:48.438098Z","iopub.execute_input":"2022-12-16T15:20:48.438702Z","iopub.status.idle":"2022-12-16T15:20:48.462967Z","shell.execute_reply.started":"2022-12-16T15:20:48.438647Z","shell.execute_reply":"2022-12-16T15:20:48.462083Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# delete rows presenting a few Nans \nto_drop = ['depth']\ndf = df.na.drop(subset = to_drop)","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:20:48.464134Z","iopub.execute_input":"2022-12-16T15:20:48.465742Z","iopub.status.idle":"2022-12-16T15:20:48.556883Z","shell.execute_reply.started":"2022-12-16T15:20:48.465691Z","shell.execute_reply":"2022-12-16T15:20:48.555630Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# for status and we directly delete the columns (not so informtive)\ndf = df.drop( 'place','status')","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:20:48.558983Z","iopub.execute_input":"2022-12-16T15:20:48.559815Z","iopub.status.idle":"2022-12-16T15:20:48.578366Z","shell.execute_reply.started":"2022-12-16T15:20:48.559767Z","shell.execute_reply":"2022-12-16T15:20:48.577176Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Let's look at the distinct types of columns, so as to have an idea of the percentages\n#df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns)).show()\nfrom pyspark.sql.functions import *\nimport pyspark.sql.functions as F\n#F.round((F.col('Month_start')/F.col('Month_end'))*100,2))\nperc = df.select(*(F.round(((sum(col(c).isNull().cast(\"int\")))/count(lit(1))*100),2).alias(c) for c in df.columns))\nperc.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:20:48.579545Z","iopub.execute_input":"2022-12-16T15:20:48.579944Z","iopub.status.idle":"2022-12-16T15:21:23.962080Z","shell.execute_reply.started":"2022-12-16T15:20:48.579903Z","shell.execute_reply":"2022-12-16T15:21:23.960771Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"22/12/16 15:20:49 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n Header: , time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\n Schema: _c0, time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\nExpected: _c0 but found: \nCSV file: file:///kaggle/input/earthquakes/consolidated_data.csv\n","output_type":"stream"},{"name":"stderr","text":"[Stage 21:>                                                         (0 + 4) / 5]\r","output_type":"stream"},{"name":"stdout","text":"22/12/16 15:20:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:20:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n","output_type":"stream"},{"name":"stderr","text":"[Stage 23:================================================>         (5 + 1) / 6]\r","output_type":"stream"},{"name":"stdout","text":"+---+----+--------+---------+-----+---+-------+----+-----+-----+----+---+----+---------------+----------+--------+------+\n|_c0|time|latitude|longitude|depth|mag|magType| nst|  gap| dmin| rms|net|type|horizontalError|depthError|magError|magNst|\n+---+----+--------+---------+-----+---+-------+----+-----+-----+----+---+----+---------------+----------+--------+------+\n|0.0| 0.0|     0.0|      0.0|  0.0|0.0|    0.0|26.3|24.66|39.48|6.17|0.0| 0.0|          45.03|     16.74|   51.95| 26.45|\n+---+----+--------+---------+-----+---+-------+----+-----+-----+----+---+----+---------------+----------+--------+------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Current situation\n**nst** --> 26%\n**gap** --> 23%\n**dmin** --> 40%\n**rms** --> 6%\n**horizontalError** --> 45%\n**depthError** --> 11%\n**magError** --> 52%\n**magNst** --> 22%","metadata":{}},{"cell_type":"code","source":"#Remove columns presenting too many missing values: dmin, horizontalError, magError\ndf = df.drop('dmin', 'horizontalError', 'magError')\n#Remove missing values on rms (only 6%)\ndf = df.na.drop(subset=['rms'])","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:21:23.963362Z","iopub.execute_input":"2022-12-16T15:21:23.966273Z","iopub.status.idle":"2022-12-16T15:21:23.994112Z","shell.execute_reply.started":"2022-12-16T15:21:23.966220Z","shell.execute_reply":"2022-12-16T15:21:23.992852Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"perc = df.select(*(F.round(((sum(col(c).isNull().cast(\"int\")))/count(lit(1))*100),2).alias(c) for c in df.columns))\nperc.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:21:24.003034Z","iopub.execute_input":"2022-12-16T15:21:24.004345Z","iopub.status.idle":"2022-12-16T15:21:59.511773Z","shell.execute_reply.started":"2022-12-16T15:21:24.004279Z","shell.execute_reply":"2022-12-16T15:21:59.510203Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"22/12/16 15:21:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n Header: , time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\n Schema: _c0, time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\nExpected: _c0 but found: \nCSV file: file:///kaggle/input/earthquakes/consolidated_data.csv\n","output_type":"stream"},{"name":"stderr","text":"[Stage 27:>                                                         (0 + 4) / 5]\r","output_type":"stream"},{"name":"stdout","text":"22/12/16 15:21:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:21:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n","output_type":"stream"},{"name":"stderr","text":"[Stage 29:================================================>         (5 + 1) / 6]\r","output_type":"stream"},{"name":"stdout","text":"+---+----+--------+---------+-----+---+-------+-----+-----+---+---+----+----------+------+\n|_c0|time|latitude|longitude|depth|mag|magType|  nst|  gap|rms|net|type|depthError|magNst|\n+---+----+--------+---------+-----+---+-------+-----+-----+---+---+----+----------+------+\n|0.0| 0.0|     0.0|      0.0|  0.0|0.0|    0.0|25.67|23.01|0.0|0.0| 0.0|     11.27| 22.01|\n+---+----+--------+---------+-----+---+-------+-----+-----+---+---+----+----------+------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"df.count()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:21:59.513498Z","iopub.execute_input":"2022-12-16T15:21:59.514401Z","iopub.status.idle":"2022-12-16T15:22:31.094591Z","shell.execute_reply.started":"2022-12-16T15:21:59.514351Z","shell.execute_reply":"2022-12-16T15:22:31.093501Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"2899664"},"metadata":{}}]},{"cell_type":"markdown","source":"# 3: Spot Errors","metadata":{}},{"cell_type":"code","source":"def stats(df):\n    for i in df.dtypes:\n        if(i[1] == 'int' or i[1] == 'double'):\n            df.describe(i[0]).show(truncate=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:22:31.095810Z","iopub.execute_input":"2022-12-16T15:22:31.096220Z","iopub.status.idle":"2022-12-16T15:22:31.106373Z","shell.execute_reply.started":"2022-12-16T15:22:31.096180Z","shell.execute_reply":"2022-12-16T15:22:31.104093Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"stats(df)","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:22:31.108602Z","iopub.execute_input":"2022-12-16T15:22:31.109548Z","iopub.status.idle":"2022-12-16T15:27:44.512977Z","shell.execute_reply.started":"2022-12-16T15:22:31.109500Z","shell.execute_reply":"2022-12-16T15:27:44.511853Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"22/12/16 15:22:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n Header: , time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\n Schema: _c0, time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\nExpected: _c0 but found: \nCSV file: file:///kaggle/input/earthquakes/consolidated_data.csv\n","output_type":"stream"},{"name":"stderr","text":"[Stage 39:>                                                         (0 + 4) / 5]\r","output_type":"stream"},{"name":"stdout","text":"22/12/16 15:22:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:22:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:22:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:22:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:22:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:22:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:22:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:22:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:22:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+-------+------------------+\n|summary|_c0               |\n+-------+------------------+\n|count  |2899664           |\n|mean   |1631868.2860765937|\n|stddev |945401.3232190389 |\n|min    |0                 |\n|max    |3272773           |\n+-------+------------------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+-------+------------------+\n|summary|latitude          |\n+-------+------------------+\n|count  |2899664           |\n|mean   |37.10635068675379 |\n|stddev |18.509435937673196|\n|min    |-84.42200000000001|\n|max    |87.221            |\n+-------+------------------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+-------+-------------------+\n|summary|longitude          |\n+-------+-------------------+\n|count  |2899664            |\n|mean   |-99.23720517124138 |\n|stddev |76.03691288465575  |\n|min    |-179.99900000000002|\n|max    |180.0              |\n+-------+-------------------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+-------+------------------+\n|summary|depth             |\n+-------+------------------+\n|count  |2899664           |\n|mean   |20.685304325673407|\n|stddev |55.25741755884641 |\n|min    |-10.0             |\n|max    |735.8             |\n+-------+------------------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+-------+------------------+\n|summary|mag               |\n+-------+------------------+\n|count  |2899664           |\n|mean   |1.7847489916075459|\n|stddev |1.3085229613371214|\n|min    |-9.99             |\n|max    |9.1               |\n+-------+------------------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+-------+------------------+\n|summary|nst               |\n+-------+------------------+\n|count  |2155437           |\n|mean   |15.989824801188808|\n|stddev |26.720432399388894|\n|min    |0.0               |\n|max    |934.0             |\n+-------+------------------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+-------+------------------+\n|summary|gap               |\n+-------+------------------+\n|count  |2232441           |\n|mean   |126.67369488862093|\n|stddev |67.42756857368224 |\n|min    |0.0               |\n|max    |360.0             |\n+-------+------------------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+-------+-------------------+\n|summary|rms                |\n+-------+-------------------+\n|count  |2899664            |\n|mean   |0.30964346338056215|\n|stddev |0.38575488697807125|\n|min    |-1.0               |\n|max    |104.33             |\n+-------+-------------------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+-------+------------------+\n|summary|depthError        |\n+-------+------------------+\n|count  |2572770           |\n|mean   |5.6276865655315325|\n|stddev |1188.7877753397745|\n|min    |-1.0              |\n|max    |1773552.5         |\n+-------+------------------+\n\n","output_type":"stream"},{"name":"stderr","text":"[Stage 95:==============================================>           (4 + 1) / 5]\r","output_type":"stream"},{"name":"stdout","text":"+-------+------------------+\n|summary|magNst            |\n+-------+------------------+\n|count  |2261327           |\n|mean   |12.594240019245337|\n|stddev |21.065921641663053|\n|min    |0.0               |\n|max    |941.0             |\n+-------+------------------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"## Considerations: \n- **depth**: some values are around -10 and this is an error for sure: drop such values.\n- **mag** : https://it.wikipedia.org/wiki/Scala_Richter http://www.blueplanetheart.it/2018/12/perche-esistono-la-magnitudo-0-0-la-magnitudo-negativa/ some values can be negative, but they are not proper sismic waves. Some values could also be caused by events for which the magnitudo is quite low. Let's make a groupby\n- **nst**: some values are 0, but they are many values. Keep them.\n- **gap**: Typical Values\n[0.0, 180.0]\nDescription:\nThe largest azimuthal gap between azimuthally adjacent stations (in degrees). In general, the smaller this number, the more reliable is the calculated horizontal position of the earthquake. Earthquake locations in which the azimuthal gap exceeds 180 degrees typically have large location and depth uncertainties.\n- **rms**: Typical Values\n[0.13,1.39]\nDescription\nThe root-mean-square (RMS) travel time residual, in sec, using all weights. This parameter provides a measure of the fit of the observed arrival times to the predicted arrival times for this location. Smaller numbers reflect a better fit of the data. The value is dependent on the accuracy of the velocity model used to compute the earthquake location, the quality weights assigned to the arrival time data, and the procedure used to locate the earthquake.\n- **depthError**: Typical Values\n[0, 100]\nDescription\nUncertainty of reported depth of the event in kilometers.\nAdditional Information\nThe depth error, in km, defined as the largest projection of the three principal errors on a vertical line.\n- **magNst**:  same for nst","metadata":{}},{"cell_type":"code","source":"#MAG\ndf.groupBy(\"mag\",\"type\").count().orderBy(col(\"mag\").asc()).show(150,truncate=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:27:44.514207Z","iopub.execute_input":"2022-12-16T15:27:44.514605Z","iopub.status.idle":"2022-12-16T15:28:21.216978Z","shell.execute_reply.started":"2022-12-16T15:27:44.514566Z","shell.execute_reply":"2022-12-16T15:28:21.215624Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"[Stage 101:>                                                        (0 + 4) / 5]\r","output_type":"stream"},{"name":"stdout","text":"22/12/16 15:28:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:28:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:28:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:28:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:28:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:28:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:28:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:28:15 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n","output_type":"stream"},{"name":"stderr","text":"[Stage 101:=============================================>           (4 + 1) / 5]\r","output_type":"stream"},{"name":"stdout","text":"+-----+------------+-----+\n|mag  |type        |count|\n+-----+------------+-----+\n|-9.99|earthquake  |670  |\n|-5.0 |other event |1    |\n|-3.0 |earthquake  |1    |\n|-2.6 |earthquake  |2    |\n|-2.5 |earthquake  |4    |\n|-2.2 |earthquake  |1    |\n|-2.0 |earthquake  |4    |\n|-1.9 |earthquake  |5    |\n|-1.8 |earthquake  |5    |\n|-1.76|earthquake  |1    |\n|-1.7 |earthquake  |4    |\n|-1.6 |earthquake  |105  |\n|-1.56|earthquake  |1    |\n|-1.51|earthquake  |1    |\n|-1.5 |earthquake  |18   |\n|-1.4 |earthquake  |36   |\n|-1.39|earthquake  |3    |\n|-1.33|earthquake  |1    |\n|-1.31|earthquake  |1    |\n|-1.3 |earthquake  |142  |\n|-1.29|earthquake  |2    |\n|-1.28|earthquake  |1    |\n|-1.27|earthquake  |1    |\n|-1.24|earthquake  |3    |\n|-1.23|earthquake  |3    |\n|-1.22|earthquake  |1    |\n|-1.21|earthquake  |2    |\n|-1.2 |earthquake  |85   |\n|-1.19|earthquake  |3    |\n|-1.18|earthquake  |1    |\n|-1.17|earthquake  |4    |\n|-1.16|earthquake  |1    |\n|-1.15|earthquake  |2    |\n|-1.14|earthquake  |1    |\n|-1.13|earthquake  |3    |\n|-1.12|earthquake  |1    |\n|-1.11|earthquake  |4    |\n|-1.1 |earthquake  |670  |\n|-1.09|earthquake  |5    |\n|-1.08|earthquake  |5    |\n|-1.07|earthquake  |12   |\n|-1.06|earthquake  |10   |\n|-1.05|earthquake  |14   |\n|-1.04|earthquake  |13   |\n|-1.03|earthquake  |12   |\n|-1.02|earthquake  |9    |\n|-1.01|earthquake  |11   |\n|-1.0 |earthquake  |437  |\n|-1.0 |quarry blast|6    |\n|-0.99|earthquake  |14   |\n|-0.98|earthquake  |14   |\n|-0.97|earthquake  |11   |\n|-0.96|earthquake  |15   |\n|-0.95|earthquake  |7    |\n|-0.94|earthquake  |18   |\n|-0.93|earthquake  |19   |\n|-0.92|earthquake  |14   |\n|-0.91|earthquake  |19   |\n|-0.9 |earthquake  |1054 |\n|-0.89|earthquake  |12   |\n|-0.88|earthquake  |21   |\n|-0.87|earthquake  |15   |\n|-0.86|earthquake  |26   |\n|-0.85|earthquake  |17   |\n|-0.84|earthquake  |15   |\n|-0.83|earthquake  |20   |\n|-0.82|earthquake  |17   |\n|-0.81|earthquake  |30   |\n|-0.8 |earthquake  |1961 |\n|-0.8 |explosion   |1    |\n|-0.79|earthquake  |17   |\n|-0.78|earthquake  |20   |\n|-0.77|earthquake  |24   |\n|-0.76|earthquake  |32   |\n|-0.75|earthquake  |22   |\n|-0.74|earthquake  |24   |\n|-0.73|earthquake  |33   |\n|-0.72|earthquake  |24   |\n|-0.71|earthquake  |31   |\n|-0.7 |explosion   |1    |\n|-0.7 |earthquake  |1528 |\n|-0.69|earthquake  |31   |\n|-0.68|earthquake  |34   |\n|-0.67|earthquake  |45   |\n|-0.66|earthquake  |34   |\n|-0.65|earthquake  |41   |\n|-0.64|earthquake  |31   |\n|-0.63|earthquake  |40   |\n|-0.62|earthquake  |48   |\n|-0.61|earthquake  |48   |\n|-0.6 |earthquake  |2996 |\n|-0.6 |quarry blast|1    |\n|-0.6 |explosion   |1    |\n|-0.59|earthquake  |46   |\n|-0.58|earthquake  |61   |\n|-0.57|earthquake  |69   |\n|-0.56|earthquake  |70   |\n|-0.56|quarry blast|1    |\n|-0.55|earthquake  |57   |\n|-0.54|quarry blast|1    |\n|-0.54|earthquake  |62   |\n|-0.53|earthquake  |49   |\n|-0.52|quarry blast|1    |\n|-0.52|earthquake  |67   |\n|-0.51|earthquake  |88   |\n|-0.5 |other event |1    |\n|-0.5 |earthquake  |4724 |\n|-0.5 |explosion   |4    |\n|-0.49|earthquake  |95   |\n|-0.48|earthquake  |76   |\n|-0.48|quarry blast|1    |\n|-0.47|earthquake  |81   |\n|-0.46|earthquake  |89   |\n|-0.46|quarry blast|2    |\n|-0.45|earthquake  |96   |\n|-0.44|quarry blast|1    |\n|-0.44|earthquake  |96   |\n|-0.43|earthquake  |88   |\n|-0.42|quarry blast|1    |\n|-0.42|earthquake  |117  |\n|-0.41|earthquake  |116  |\n|-0.4 |earthquake  |5427 |\n|-0.4 |explosion   |2    |\n|-0.39|earthquake  |126  |\n|-0.39|quarry blast|2    |\n|-0.38|quarry blast|2    |\n|-0.38|earthquake  |133  |\n|-0.37|earthquake  |139  |\n|-0.36|quarry blast|2    |\n|-0.36|earthquake  |130  |\n|-0.36|explosion   |1    |\n|-0.35|earthquake  |145  |\n|-0.34|earthquake  |138  |\n|-0.33|earthquake  |179  |\n|-0.33|quarry blast|1    |\n|-0.32|quarry blast|2    |\n|-0.32|earthquake  |162  |\n|-0.31|earthquake  |151  |\n|-0.3 |earthquake  |9011 |\n|-0.3 |other event |1    |\n|-0.3 |explosion   |4    |\n|-0.29|quarry blast|2    |\n|-0.29|earthquake  |166  |\n|-0.28|earthquake  |162  |\n|-0.28|quarry blast|1    |\n|-0.27|earthquake  |215  |\n|-0.26|earthquake  |219  |\n|-0.25|earthquake  |208  |\n|-0.24|earthquake  |210  |\n|-0.23|earthquake  |211  |\n+-----+------------+-----+\nonly showing top 150 rows\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"#NST\ndf.createOrReplaceTempView(\"dff\")\nspark.sql(\"select time,latitude,longitude,type from dff where nst = 0.0\").show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:28:21.218301Z","iopub.execute_input":"2022-12-16T15:28:21.219151Z","iopub.status.idle":"2022-12-16T15:28:33.211642Z","shell.execute_reply.started":"2022-12-16T15:28:21.219102Z","shell.execute_reply":"2022-12-16T15:28:33.210423Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"[Stage 105:=============================================>           (4 + 1) / 5]\r","output_type":"stream"},{"name":"stdout","text":"+--------------------+------------------+-------------------+------------+\n|                time|          latitude|          longitude|        type|\n+--------------------+------------------+-------------------+------------+\n|1971-02-09 16:41:...|            34.416|            -118.37|  earthquake|\n|1975-01-25 15:02:...|            32.995|           -115.505|  earthquake|\n|1975-02-27 16:43:...|            34.427|           -118.406|  earthquake|\n|1975-04-02 22:33:...|            33.548|-116.52799999999999|  earthquake|\n|1975-04-21 15:41:...|            34.486|            -116.45|  earthquake|\n|1975-06-01 02:01:...|            34.509|           -116.479|  earthquake|\n|1975-06-17 16:03:...|             32.79|           -115.449|  earthquake|\n|1975-06-20 23:26:...|            32.775|-115.43799999999999|  earthquake|\n|1975-06-23 04:27:...|            32.893|           -115.523|  earthquake|\n|1975-07-21 16:51:...|            33.729|           -116.846|  earthquake|\n|1975-07-25 14:11:...|            32.883|-115.52600000000001|  earthquake|\n|1975-08-01 22:25:...|33.663000000000004|           -116.706|  earthquake|\n|1975-09-05 16:12:...|            34.454|-118.34200000000001|quarry blast|\n|1975-10-11 17:39:...|            34.539|           -116.434|  earthquake|\n|1976-01-30 10:48:...|34.150999999999996|-115.76899999999999|  earthquake|\n|1976-02-20 07:35:...|            33.817|-115.68700000000001|  earthquake|\n| 1976-02-20 11:30:05|33.955999999999996|-116.27799999999999|  earthquake|\n|1976-03-06 15:06:...|34.138000000000005|           -117.399|  earthquake|\n|1976-04-06 07:31:...|32.751999999999995|           -115.441|  earthquake|\n|1976-04-06 09:54:...|            32.937|           -115.554|  earthquake|\n+--------------------+------------------+-------------------+------------+\nonly showing top 20 rows\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"#NST\ndf.groupBy(\"nst\").count().orderBy(col(\"nst\").asc()).show(50,truncate=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:28:33.212911Z","iopub.execute_input":"2022-12-16T15:28:33.213392Z","iopub.status.idle":"2022-12-16T15:29:07.985435Z","shell.execute_reply.started":"2022-12-16T15:28:33.213345Z","shell.execute_reply":"2022-12-16T15:29:07.984102Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"[Stage 110:>                                                        (0 + 4) / 5]\r","output_type":"stream"},{"name":"stdout","text":"22/12/16 15:29:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:29:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:29:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:29:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:29:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:29:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:29:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:29:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n","output_type":"stream"},{"name":"stderr","text":"[Stage 110:=============================================>           (4 + 1) / 5]\r","output_type":"stream"},{"name":"stdout","text":"+----+------+\n|nst |count |\n+----+------+\n|null|744227|\n|0.0 |283801|\n|1.0 |40    |\n|2.0 |1836  |\n|3.0 |27409 |\n|4.0 |88082 |\n|5.0 |119494|\n|6.0 |129435|\n|7.0 |132318|\n|8.0 |122438|\n|9.0 |110796|\n|10.0|98898 |\n|11.0|88487 |\n|12.0|78436 |\n|13.0|70012 |\n|14.0|63546 |\n|15.0|56900 |\n|16.0|52065 |\n|17.0|48070 |\n|18.0|43433 |\n|19.0|39480 |\n|20.0|36193 |\n|21.0|32943 |\n|22.0|30181 |\n|23.0|27427 |\n|24.0|24750 |\n|25.0|22660 |\n|26.0|20774 |\n|27.0|19048 |\n|28.0|17462 |\n|29.0|16044 |\n|30.0|14848 |\n|31.0|14168 |\n|32.0|12767 |\n|33.0|11539 |\n|34.0|10840 |\n|35.0|10177 |\n|36.0|9412  |\n|37.0|8868  |\n|38.0|8165  |\n|39.0|7891  |\n|40.0|7328  |\n|41.0|6874  |\n|42.0|6420  |\n|43.0|6065  |\n|44.0|5583  |\n|45.0|5322  |\n|46.0|5043  |\n|47.0|4613  |\n|48.0|4305  |\n+----+------+\nonly showing top 50 rows\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"#GAP\ndf.createOrReplaceTempView(\"dff\")\nspark.sql(\"select count(*) from dff where gap > 180\").show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:29:07.986774Z","iopub.execute_input":"2022-12-16T15:29:07.987400Z","iopub.status.idle":"2022-12-16T15:29:22.740538Z","shell.execute_reply.started":"2022-12-16T15:29:07.987352Z","shell.execute_reply":"2022-12-16T15:29:22.738292Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"[Stage 114:=============================================>           (4 + 1) / 5]\r","output_type":"stream"},{"name":"stdout","text":"+--------+\n|count(1)|\n+--------+\n|  435377|\n+--------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"#RMS --> remember this is a temporal feature: drop negarive values\ndf.createOrReplaceTempView(\"dff\")\nspark.sql(\"select count(*) from dff where rms < 0\").show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:29:22.741843Z","iopub.execute_input":"2022-12-16T15:29:22.742308Z","iopub.status.idle":"2022-12-16T15:29:33.941463Z","shell.execute_reply.started":"2022-12-16T15:29:22.742263Z","shell.execute_reply":"2022-12-16T15:29:33.940158Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"[Stage 120:=============================================>           (4 + 1) / 5]\r","output_type":"stream"},{"name":"stdout","text":"+--------+\n|count(1)|\n+--------+\n|       3|\n+--------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"#RMS\ndf.createOrReplaceTempView(\"dff\")\nspark.sql(\"select rms,count(*) from dff where rms > 10 group by rms order by rms asc\").show(150)","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:29:33.942472Z","iopub.execute_input":"2022-12-16T15:29:33.942796Z","iopub.status.idle":"2022-12-16T15:29:44.913765Z","shell.execute_reply.started":"2022-12-16T15:29:33.942762Z","shell.execute_reply":"2022-12-16T15:29:44.912568Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"[Stage 126:=============================================>           (4 + 1) / 5]\r","output_type":"stream"},{"name":"stdout","text":"+------------------+--------+\n|               rms|count(1)|\n+------------------+--------+\n|             10.07|       1|\n|             10.22|       1|\n|             10.26|       1|\n|            10.261|       1|\n|             10.32|       1|\n|             10.39|       1|\n|10.562999999999999|       1|\n|             10.59|       1|\n|            10.659|       1|\n|             10.72|       1|\n|             10.94|       1|\n|             10.96|       1|\n|              11.0|       1|\n|            11.019|       1|\n|             11.02|       1|\n|             11.08|       1|\n|              11.1|       1|\n|            11.155|       1|\n|             11.23|       1|\n|             11.38|       1|\n|            11.413|       1|\n|             11.54|       1|\n|             11.57|       1|\n|            11.741|       1|\n|             11.95|       1|\n|            11.954|       1|\n|             12.02|       1|\n|             12.09|       1|\n|            12.169|       1|\n|              12.4|       1|\n|             12.46|       1|\n|            12.519|       1|\n|             12.88|       1|\n|              12.9|       1|\n|             13.39|       1|\n|             13.54|       1|\n|             13.57|       1|\n|             13.63|       1|\n|             13.79|       1|\n|              13.9|       1|\n|             13.97|       1|\n|             13.99|       1|\n|             14.07|       1|\n|             15.32|       1|\n|             15.43|       1|\n|             15.57|       1|\n|              15.6|       1|\n|             15.78|       1|\n|             15.93|       1|\n|             16.07|       1|\n|             16.11|       1|\n|             16.13|       1|\n|             16.46|       1|\n|             16.55|       1|\n|             16.71|       1|\n|             17.55|       2|\n|              17.6|       1|\n|             17.72|       1|\n|             17.75|       1|\n|             17.93|       1|\n|17.999000000000002|       1|\n|             18.34|       1|\n|            18.711|       1|\n|             18.85|       1|\n|             19.02|       1|\n|             19.28|       1|\n|            19.382|       1|\n|19.410999999999998|       1|\n|            19.566|       1|\n|             20.02|       1|\n|             20.08|       1|\n|20.541999999999998|       1|\n|             20.58|       1|\n|             20.79|       1|\n|             20.83|       1|\n|             21.02|       1|\n|             21.55|       1|\n|             21.78|       1|\n|            22.419|       1|\n|             23.23|       1|\n|             25.07|       1|\n|              26.1|       1|\n|             27.05|       1|\n|             30.63|       1|\n|             33.66|       1|\n|            36.046|       1|\n|             36.77|       1|\n|             39.25|       1|\n|             40.86|       1|\n|             41.96|       1|\n|             44.08|       1|\n|             44.51|       1|\n|              50.5|       1|\n|             53.97|       1|\n|             54.64|       1|\n|             64.29|       1|\n|             69.32|       1|\n|             71.45|       1|\n|            104.33|       1|\n+------------------+--------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"#DEPTHERROR : cannot be negative\ndf.createOrReplaceTempView(\"dff\")\nspark.sql(\"select count(*) from dff where depthError < 0\").show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:29:44.915116Z","iopub.execute_input":"2022-12-16T15:29:44.915557Z","iopub.status.idle":"2022-12-16T15:29:59.178904Z","shell.execute_reply.started":"2022-12-16T15:29:44.915500Z","shell.execute_reply":"2022-12-16T15:29:59.177691Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"[Stage 132:=============================================>           (4 + 1) / 5]\r","output_type":"stream"},{"name":"stdout","text":"+--------+\n|count(1)|\n+--------+\n|       3|\n+--------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"#DEPTHERROR \ndf.createOrReplaceTempView(\"dff\")\nspark.sql(\"select count(*) from dff where depthError > 600\").show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:29:59.180149Z","iopub.execute_input":"2022-12-16T15:29:59.180479Z","iopub.status.idle":"2022-12-16T15:30:13.446522Z","shell.execute_reply.started":"2022-12-16T15:29:59.180449Z","shell.execute_reply":"2022-12-16T15:30:13.445263Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"[Stage 138:=============================================>           (4 + 1) / 5]\r","output_type":"stream"},{"name":"stdout","text":"+--------+\n|count(1)|\n+--------+\n|     444|\n+--------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"#DEPTHERROR \ndf.createOrReplaceTempView(\"dff\")\nspark.sql(\"select count(*) from dff where depthError > 1000\").show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:30:13.447799Z","iopub.execute_input":"2022-12-16T15:30:13.448296Z","iopub.status.idle":"2022-12-16T15:30:27.785484Z","shell.execute_reply.started":"2022-12-16T15:30:13.448243Z","shell.execute_reply":"2022-12-16T15:30:27.784655Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"[Stage 144:=============================================>           (4 + 1) / 5]\r","output_type":"stream"},{"name":"stdout","text":"+--------+\n|count(1)|\n+--------+\n|     291|\n+--------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"#MAGNST\ndf.createOrReplaceTempView(\"dff\")\nspark.sql(\"select count(*) from dff where magNst = 0.0\").show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:30:27.786358Z","iopub.execute_input":"2022-12-16T15:30:27.786678Z","iopub.status.idle":"2022-12-16T15:30:43.293063Z","shell.execute_reply.started":"2022-12-16T15:30:27.786649Z","shell.execute_reply":"2022-12-16T15:30:43.292198Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"[Stage 150:=============================================>           (4 + 1) / 5]\r","output_type":"stream"},{"name":"stdout","text":"+--------+\n|count(1)|\n+--------+\n|  106598|\n+--------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"### FINAL DF","metadata":{}},{"cell_type":"code","source":"df = df.filter((df.depth > -6) & (df.mag >= -1) & (df.rms >= 0) &(df.depthError >= 0) & (df.depthError <= 500))  #totake\ndf.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:30:43.294030Z","iopub.execute_input":"2022-12-16T15:30:43.294495Z","iopub.status.idle":"2022-12-16T15:31:14.494385Z","shell.execute_reply.started":"2022-12-16T15:30:43.294449Z","shell.execute_reply":"2022-12-16T15:31:14.491886Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"22/12/16 15:30:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n Header: , time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\n Schema: _c0, time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\nExpected: _c0 but found: \nCSV file: file:///kaggle/input/earthquakes/consolidated_data.csv\n","output_type":"stream"},{"name":"stderr","text":"[Stage 156:>                                                        (0 + 4) / 5]\r","output_type":"stream"},{"name":"stdout","text":"22/12/16 15:30:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:30:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:30:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:30:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:30:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:31:00 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n","output_type":"stream"},{"name":"stderr","text":"[Stage 158:>                                                        (0 + 1) / 1]\r","output_type":"stream"},{"name":"stdout","text":"+-------+--------------------+------------------+-------------------+--------------------+----+-------+----+-----+----+---+----------+----------+------+\n|    _c0|                time|          latitude|          longitude|               depth| mag|magType| nst|  gap| rms|net|      type|depthError|magNst|\n+-------+--------------------+------------------+-------------------+--------------------+----+-------+----+-----+----+---+----------+----------+------+\n| 988433|1970-01-12 08:42:...|           33.1405|-116.16766670000001|                 6.0|2.42|     mh| 6.0|129.0|0.53| ci|earthquake|     31.61|   9.0|\n|1560841|1970-04-20 07:31:...|        34.4058333|           -118.557|                 1.5|2.65|     ml| 9.0|149.0|0.47| ci|earthquake|       2.1|   7.0|\n| 774426|1970-09-04 05:57:...| 46.68600000000001|            -119.61|               4.555| 1.2|     md| 6.0|123.0|0.32| uw|earthquake|      9.09|   5.0|\n| 774375|1970-09-15 22:30:...|        34.2436667|-117.50083329999998|                8.79|3.21|     ml| 8.0|120.0|0.52| ci|earthquake|      3.33|   8.0|\n|2003193|1970-12-26 11:44:...| 47.54600000000001|           -122.775|  18.430999999999997| 2.2|     md| 5.0|104.0|0.07| uw|earthquake|      0.55|   5.0|\n|1378733|1971-02-21 13:56:...|47.771333299999995|           -122.089|               7.727| 2.2|     md| 4.0|228.0|0.15| uw|earthquake|      99.9|   4.0|\n|2587309|1971-04-19 11:15:...|            34.293|          -116.5755|                 6.0|2.77|     ml| 6.0|205.0|0.47| ci|earthquake|     31.61|   5.0|\n|2115812|1972-11-25 07:07:...|33.973833299999995|-117.62966670000002|                0.04|3.36|     ml|15.0|129.0|0.39| ci|earthquake|      1.51|  11.0|\n| 429731|1973-01-27 16:29:...|46.641999999999996|-118.89933329999998|              -0.094| 1.1|     md| 7.0|238.0|0.12| uw|earthquake|      1.05|   7.0|\n|2806368|1973-02-18 01:06:...|47.774333299999995|-122.55516670000002|              22.483| 1.5|     md| 6.0| 95.0|0.12| uw|earthquake|      2.58|   3.0|\n|1966138|1973-03-06 08:20:...|           46.8705|-119.35666670000002|              -0.293| 1.2|     md|10.0|171.0|0.17| uw|earthquake|      0.05|  10.0|\n|3044564|1973-08-18 15:59:...|           33.7905|          -117.8155|                 6.0|2.29|     mh| 7.0|175.0|0.62| ci|earthquake|     31.61|  11.0|\n|3044548|1973-08-20 03:47:...|        34.3716667|-118.26983329999999|                0.67|3.53|     ml|11.0|115.0|0.41| ci|earthquake|      1.77|   8.0|\n|3079144|1973-10-25 11:32:...|47.612333299999996|          -122.3285|-0.20600000000000002| 2.6|     md| 9.0| 88.0|0.17| uw|earthquake|       1.3|   9.0|\n|3173743|1973-12-24 03:33:...|        47.6931667|          -121.7245|              12.305| 1.2|     md| 4.0|192.0|0.09| uw|earthquake|      2.72|   4.0|\n| 137291|1974-01-12 02:24:...|33.967833299999995|-118.98066670000001|                 6.0|2.47|     ml|10.0|197.0|0.47| ci|earthquake|     31.61|   5.0|\n| 137269|1974-01-13 11:28:...|            36.577|-121.19083329999998|   6.882999999999999|2.19|     md| 8.0| 94.0|0.05| nc|earthquake|       0.8|   3.0|\n| 137149|1974-01-19 01:26:...|        37.2601667|-121.64233329999999|               4.933|2.71|     md|34.0| 82.0|0.06| nc|earthquake|       0.5|  13.0|\n| 518586|1974-04-06 11:36:...|            36.606|-121.21516670000001|  5.3020000000000005|1.37|     md|10.0| 87.0|0.03| nc|earthquake|      0.68|   4.0|\n| 518472|1974-04-11 20:18:...|        37.2843333|-121.64383329999998|               6.041|1.81|     md| 7.0|171.0|0.05| nc|earthquake|      1.28|   4.0|\n+-------+--------------------+------------------+-------------------+--------------------+----+-------+----+-----+----+---+----------+----------+------+\nonly showing top 20 rows\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"df.count()","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:31:14.495655Z","iopub.execute_input":"2022-12-16T15:31:14.496110Z","iopub.status.idle":"2022-12-16T15:31:47.311051Z","shell.execute_reply.started":"2022-12-16T15:31:14.496065Z","shell.execute_reply":"2022-12-16T15:31:47.309852Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"2570408"},"metadata":{}}]},{"cell_type":"code","source":"df.repartition(1).write.option(\"header\",True).csv(\"DDAM_Pyspark.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-12-16T15:31:47.313022Z","iopub.execute_input":"2022-12-16T15:31:47.313445Z","iopub.status.idle":"2022-12-16T15:32:41.796737Z","shell.execute_reply.started":"2022-12-16T15:31:47.313402Z","shell.execute_reply":"2022-12-16T15:32:41.794254Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"22/12/16 15:31:47 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n Header: , time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\n Schema: _c0, time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource\nExpected: _c0 but found: \nCSV file: file:///kaggle/input/earthquakes/consolidated_data.csv\n","output_type":"stream"},{"name":"stderr","text":"[Stage 165:>                                                        (0 + 4) / 5]\r","output_type":"stream"},{"name":"stdout","text":"22/12/16 15:31:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:31:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:31:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:31:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:31:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n22/12/16 15:32:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}